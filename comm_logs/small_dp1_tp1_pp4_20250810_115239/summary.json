{
  "config": {
    "model_size": "small",
    "model_config": {
      "hidden_size": 768,
      "num_layers": 12,
      "num_attention_heads": 12,
      "seq_length": 1024
    },
    "data_parallel_size": 1,
    "tensor_model_parallel_size": 1,
    "pipeline_model_parallel_size": 4,
    "context_parallel_size": 1,
    "world_size": 4,
    "seed": 1234,
    "timestamp": "20250810_115239",
    "num_micro_batches": 4,
    "global_batch_size": 16
  },
  "log_files": [
    "comm_log_rank_0.json",
    "comm_log_rank_1.json",
    "comm_log_rank_2.json",
    "comm_log_rank_3.json"
  ]
}