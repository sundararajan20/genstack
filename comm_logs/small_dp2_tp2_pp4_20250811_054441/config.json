{
  "model_size": "small",
  "model_config": {
    "hidden_size": 768,
    "num_layers": 12,
    "num_attention_heads": 12,
    "seq_length": 1024
  },
  "data_parallel_size": 2,
  "tensor_model_parallel_size": 2,
  "pipeline_model_parallel_size": 4,
  "world_size": 16,
  "seed": 1234,
  "timestamp": "20250811_054441",
  "num_micro_batches": 4,
  "global_batch_size": 1024
}